{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hola &#x1F600;\n",
    "\n",
    "Soy **Hesus Garcia**, revisor de código de Triple Ten, y voy a examinar el proyecto que has desarrollado recientemente. Si encuentro algún error, te lo señalaré para que lo corrijas, ya que mi objetivo es ayudarte a prepararte para un ambiente de trabajo real, donde el líder de tu equipo actuaría de la misma manera. Si no puedes solucionar el problema, te proporcionaré más información en la próxima oportunidad. Cuando encuentres un comentario,  **por favor, no los muevas, no los modifiques ni los borres**. \n",
    "\n",
    "Revisaré cuidadosamente todas las implementaciones que has realizado para cumplir con los requisitos y te proporcionaré mis comentarios de la siguiente manera:\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=“tocSkip”></a>\n",
    "Si todo está perfecto.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario del revisor</b> <a class=“tocSkip”></a>\n",
    "Si tu código está bien pero se puede mejorar o hay algún detalle que le hace falta.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Comentario del revisor</b> <a class=“tocSkip”></a>\n",
    "Si de pronto hace falta algo o existe algún problema con tu código o conclusiones.\n",
    "</div>\n",
    "\n",
    "Puedes responderme de esta forma:\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Respuesta del estudiante</b> <a class=“tocSkip”></a>\n",
    "</div>\n",
    "\n",
    "</br>\n",
    "\n",
    "**¡Empecemos!**  &#x1F680;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se busca el calculo de la eficiencia de una minera de extracción de oro por Zyfra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import (make_scorer, mean_absolute_error)\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datasets a trabajar\n",
    "try:\n",
    "    train = pd.read_csv('gold_recovery_train.csv')\n",
    "    test = pd.read_csv('gold_recovery_test.csv')\n",
    "    full = pd.read_csv('gold_recovery_full.csv')\n",
    "except:\n",
    "    train = pd.read_csv('/datasets/gold_recovery_train.csv')\n",
    "    test = pd.read_csv('/datasets/gold_recovery_test.csv')\n",
    "    full = pd.read_csv('/datasets/gold_recovery_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.info()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.info()\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisando los datos de cada uno de los conjuntos de datos se trabajará lo siguiente:\n",
    "    1.- Columna `data` se transformará a DateTime en los tres datasets.\n",
    "    2.- Verificar los valores ausentes, al no tener los datos completos se eliminarán las filas con valores ausentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trabajará la columna `data` para transforma a tipo DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "full['date'] = pd.to_datetime(full['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan los valores ausentes en los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "full = full.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se buscará usar las mismas columnas en cada dataset para realizar el análisis de mejor forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_test = list(test.columns.values)+ ['rougher.output.recovery','final.output.recovery']\n",
    "train_df = train.loc[:,list_test]\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean las columnas de target a usar para entrenar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = full[['date','rougher.output.recovery','final.output.recovery']]\n",
    "test_df = test.merge(target_columns, how='left', on='date')\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de recuperados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar que el cálculo de recuperados es correcto se realizará un cálculo con las siguientes columnas:\n",
    "\n",
    "    - rougher.input.infeed_au La cual es la concentración inicial de oro alimentado.\n",
    "    - rougher.output.concentrate_au Concentración de oro antes de la flotación.\n",
    "    - rougher.output.tail_au Concentración de oro después de la flotación.\n",
    "\n",
    "Con estos datos se va a calcular el porcentaje de oro para cada fila del data set train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para calculo de procentaje de oro\n",
    "\n",
    "def calculo_concentrado(ini_au, conc_au, tail_au):\n",
    "    recuperado = (conc_au*(ini_au-tail_au))/(ini_au*(conc_au-tail_au))*100\n",
    "    print(recuperado.head())\n",
    "    return recuperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valores presentados en dataset\n",
    "recovery = train['rougher.output.recovery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrado = train['rougher.output.concentrate_au']\n",
    "alimentacion = train['rougher.input.feed_au']\n",
    "colas = train['rougher.output.tail_au']\n",
    "\n",
    "recuperado_calculado = calculo_concentrado(alimentacion,concentrado,colas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula el Error absoluto medio de recuperado_calculado contra recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(recuperado_calculado, recovery)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error es tan pequeño que nuestro cálculo de porcentaje de recuperación de oro es correcto, por lo que procederemos a lo siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis set de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset de prueba, no contiene las columnas referentes a la concentración de plata, plomo, solvente, oro finales.\n",
    "Así mismo tampoco tiene los datos finales de las colas de plata, plomo, solvente y oro.\n",
    "Para tener todas las características las columnas floatbank10_sulfate_to_au_feed, floatbank11_sulfate_to_au_feed, and au_pb_ratio también están ausentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de concentraciones por metal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definirá una función para mostrar los cambios de concentración de los diferentes metales (oro, plata, plomo) en las diferentes etapas del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metal_conc(data, etapas):\n",
    "    for etapa in etapas:\n",
    "        data[etapa].hist(legend=True, figsize=(9,6),alpha=0.65)\n",
    "        plt.xlabel(\"Concentración\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se definen las concentraciones de los metales en las diferentes etapas:\n",
    "\n",
    "etapa_oro = ['rougher.output.concentrate_au',\n",
    "             'primary_cleaner.output.concentrate_au',\n",
    "             'secondary_cleaner.output.tail_au',\n",
    "             'final.output.concentrate_au']\n",
    "\n",
    "etapa_plata = ['rougher.output.concentrate_ag',\n",
    "               'primary_cleaner.output.concentrate_ag',\n",
    "               'secondary_cleaner.output.tail_ag',\n",
    "               'final.output.concentrate_ag']\n",
    "\n",
    "etapa_plomo = ['rougher.output.concentrate_pb',\n",
    "               'primary_cleaner.output.concentrate_pb',\n",
    "               'secondary_cleaner.output.tail_pb',\n",
    "               'final.output.concentrate_pb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metal_conc(train,etapa_oro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_conc(train,etapa_plata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_conc(train,etapa_plomo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se muestra en los histrogramas, conforme avanza el proceso se espera tener una mayor concentración de oro, mientras que la concentración de plata y plomo disminuyen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamaño de partículas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a comparar el tamaño de partícula en los dataset de entrenamiento *(train)* y de prueba *(test)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rougher.input.feed_size'].hist(bins=50, \n",
    "                                      alpha=0.5, \n",
    "                                      label=\"Tamaño de partícula entrenamiento\")\n",
    "\n",
    "test['rougher.input.feed_size'].hist(bins=50, \n",
    "                                     alpha=0.5, \n",
    "                                     label=\"Tamaño de partícula prueba\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Tamaño de partícula\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El histograma no muestra gran diferencia en la frecuencia de los tamaños de partículas por lo que los cálculos de estimaciones serán consistentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Concentración de mezcla a diferentes etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se graficarán la sumas de las concentraciones de los metales en diferentes etapas, esto con el fin de determinar los valores fuera de rango que causarían ruido en nuestro modelo de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando del dataset full realizaremos los histogramas\n",
    "\n",
    "full['total_mixture'] = full[['rougher.input.feed_au',\n",
    "                              'rougher.input.feed_ag',\n",
    "                              'rougher.input.feed_pb']].sum(axis=1, skipna=True)\n",
    "full['total_mixture'].hist(bins=30, figsize=(9,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['total_roughermix'] = full[['rougher.output.concentrate_au',\n",
    "                                 'rougher.output.concentrate_ag',\n",
    "                                 'rougher.output.concentrate_pb']].sum(axis=1,skipna=True)\n",
    "full['total_roughermix'].hist(bins=30, figsize=(9,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['total_finalmix'] = full[['final.output.concentrate_au',\n",
    "                                 'final.output.concentrate_ag',\n",
    "                                 'final.output.concentrate_pb']].sum(axis=1,skipna=True)\n",
    "full['total_finalmix'].hist(bins=30, figsize=(9,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los histrogramas nos muestran muchos valores fuera de rango, por lo que los removeremos para no causar ruido en nuestros calculos. También se muestra que los datos están cargados hacia la derecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para buscar los valores fuera de rangos u outliers, se realizará un cálculo de los valores intercuartiles\n",
    "\n",
    "def outliers_drop(data, columnas):\n",
    "    mapeo = defaultdict(list)\n",
    "    for columna in columnas:\n",
    "        q1 = data[columna].quantile(0.25)\n",
    "        q3 = data[columna].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        minimo = q1-1.5*iqr\n",
    "        maximo = q3+1.5*iqr\n",
    "        mapeo[columna] = (minimo, maximo)\n",
    "    df = data\n",
    "    for a, b in mapeo.items():\n",
    "        df = df.loc[(df[a] > b[0]) & (df[a] < b[1])]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = ['total_mixture','total_roughermix','total_finalmix']\n",
    "\n",
    "print(full.shape)\n",
    "\n",
    "full_fin = outliers_drop(full, parametros)\n",
    "\n",
    "print(full_fin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestran los histogramas nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fin['total_mixture'].hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fin['total_roughermix'].hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fin['total_finalmix'].hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con los datos más parecidos a una distribución normal, procederemos a entrenar y probar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se agrega la columna total_mixture al dataset de entrenamiento\n",
    "columnas = full_fin[['date','total_mixture']]\n",
    "train_final = train_df.merge(columnas, how='left', on='date')\n",
    "train_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se quitan las filas con valores nulos en total_mixture\n",
    "train_final = train_final[train_final.total_mixture.notnull()]\n",
    "train_final = train_final.drop(['total_mixture'], axis=1)\n",
    "train_final.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hará lo mismo con el dataset de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = test_df.merge(columnas, how='left', on='date')\n",
    "test_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = test_final[test_final.total_mixture.notnull()]\n",
    "test_final = test_final.drop(['total_mixture'], axis=1)\n",
    "test_final.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos datasets trabajaremos los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=“tocSkip”></a>\n",
    "¡Muy bien! 👏👏 Los cálculos de esta sección están correctos y eso es un gran logro. Sigue así y verás cómo poco a poco te irás convirtiendo en un experto en esta área. 💪💻</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado y Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_cal(target, prediction):\n",
    "    \n",
    "    def smape(target, prediction):\n",
    "        smape = np.mean((np.abs(target-prediction)/((np.abs(target)+np.abs(prediction))/2)))*100\n",
    "        return smape\n",
    "    \n",
    "    smape_r = smape(target[:,0],prediction[:,0])\n",
    "    smape_f = smape(target[:,1],prediction[:,1])\n",
    "    smape_final = 0.25*smape_r + 0.75*smape_f\n",
    "    return smape_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=“tocSkip”></a>\n",
    "La función está correctamente definida. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Características y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['rougher.output.recovery','final.output.recovery']\n",
    "\n",
    "train_features = train_final.drop(targets, axis=1)\n",
    "train_target = train_final[targets]\n",
    "\n",
    "test_features = test_final.drop(targets,axis=1)\n",
    "test_target = test_final[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_scorer = make_scorer(smape_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = train_features.set_index('date')\n",
    "test_features = test_features.set_index('date')\n",
    "\n",
    "features = list(train_features.columns)\n",
    "scaler.fit(train_features[features])\n",
    "\n",
    "train_features[features] = scaler.transform(train_features[features])\n",
    "test_features[features] = scaler.transform(test_features[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=“tocSkip”></a>\n",
    "Perfecto! Preveniste el data leakage. El escalado de datos se realiza por separado para los conjuntos de entrenamiento y prueba.\n",
    "Cuando escalas tus datos, estás ajustando sus valores para que tengan una escala uniforme.\n",
    "Imagina esto: Si escalas todo el conjunto de datos (entrenamiento + prueba) juntos, es posible que los valores de prueba influyan en la escala de entrenamiento y viceversa.\n",
    "    \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model = RandomForestRegressor(random_state=1234, n_estimators=15)\n",
    "\n",
    "rfr_train_smape = cross_validate(rfr_model, train_features, train_target.to_numpy(), scoring=smape_scorer, cv=5)\n",
    "\n",
    "for a,b in rfr_train_smape.items():\n",
    "    print(a,b)\n",
    "\n",
    "score_final = rfr_train_smape['test_score']\n",
    "print(\"sMAPE promedio: \", np.sum(score_final)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_train_smape = cross_validate(lr_model, \n",
    "                                train_features, \n",
    "                                train_target.to_numpy(), \n",
    "                                scoring=smape_scorer, \n",
    "                                cv=5)\n",
    "\n",
    "for a,b in lr_train_smape.items():\n",
    "    print(a,b)\n",
    "\n",
    "score_final = lr_train_smape['test_score']\n",
    "print(\"sMAPE promedio: \", np.sum(score_final)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(1,15):\n",
    "    dcr_model = DecisionTreeRegressor(random_state=1234, max_depth=depth)\n",
    "    \n",
    "    dcr_train_smape = cross_validate(dcr_model, \n",
    "                                     train_features, \n",
    "                                     train_target.to_numpy(), \n",
    "                                     scoring=smape_scorer, \n",
    "                                     cv=5)\n",
    "    \n",
    "    for a,b in dcr_train_smape.items():\n",
    "        print(a,b)\n",
    "\n",
    "    score_final = dcr_train_smape['test_score']\n",
    "    print(\"Depth: \", depth)\n",
    "    print(\"sMAPE promedio: \", np.sum(score_final)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo DecisionTreeRegresor es el que nos arroja menor sMAPE, con una profundidad máxima de 1, por lo que utilizaremos estos valores para entrenar y probar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "\n",
    "He revisado tu implementación de los modelos RandomForestRegressor, LinearRegression y DecisionTreeRegressor, y quisiera destacar varios aspectos positivos de tu enfoque.\n",
    "\n",
    "1. <b>Selección de Modelos y Parámetros:</b> Has hecho un excelente trabajo al seleccionar una variedad de modelos  de regressón. para probar en tu conjunto de datos\n",
    "\n",
    "2. <b>Uso de Cross-Validation:</b> Tu implementación de validación cruzada fue adecuada. \n",
    "\n",
    "3. <b>Implementación del sMAPE Custom Scorer:</b> La utilización del sMAPE (Symmetric Mean Absolute Percentage Error) como métrica es adecuada para problemas de regresión, especialmente en contextos donde los errores relativos son más importantes. Además, la creación de un 'scorer' personalizado para esta métrica demuestra un nivel avanzado de habilidad en la manipulación de datos y evaluación de modelos.\n",
    "\n",
    "4. <b>Análisis y Elección del Modelo Final:</b> La decisión de elegir el modelo con el menor sMAPE promedio es lógica y bien fundamentada. Tu análisis para llegar a esta conclusión está bien articulado y muestra un razonamiento claro.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_model = DecisionTreeRegressor(random_state=1234, max_depth=1)\n",
    "\n",
    "dtr_model.fit(train_features, train_target)\n",
    "\n",
    "predict = dtr_model.predict(test_features)\n",
    "\n",
    "smape = smape_cal(test_target.to_numpy(), predict)\n",
    "print(\"sMAPE: \", smape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo nos un valor sMAPE de 6.589, menor que lo presenta la validación cruzada, con esto damos un valor de certidumbre aceptable a nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">    \n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n",
    "    \n",
    "¡Qué gran trabajo has hecho!  &#128077;  Podemos aprobar el proyecto. <br>\n",
    "Has demostrado un excelente conocimiento en la construcción de modelos, al eliminar variables innecesarias y procesar  los datos antes de entrenar los modelos. <br>\n",
    "<br>Quiero felicitarte por un trabajo excepcional y por la calidad de tu análisis. Te animo a que sigas aprendiendo y desafiando tu potencial en los próximos sprints. Estoy seguro de que tus habilidades y conocimientos serán valiosos en el futuro y te permitirán abordar problemas cada vez más complejos con éxito.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
