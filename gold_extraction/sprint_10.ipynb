{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hola &#x1F600;\n",
    "\n",
    "Soy **Hesus Garcia**, revisor de c√≥digo de Triple Ten, y voy a examinar el proyecto que has desarrollado recientemente. Si encuentro alg√∫n error, te lo se√±alar√© para que lo corrijas, ya que mi objetivo es ayudarte a prepararte para un ambiente de trabajo real, donde el l√≠der de tu equipo actuar√≠a de la misma manera. Si no puedes solucionar el problema, te proporcionar√© m√°s informaci√≥n en la pr√≥xima oportunidad. Cuando encuentres un comentario,  **por favor, no los muevas, no los modifiques ni los borres**. \n",
    "\n",
    "Revisar√© cuidadosamente todas las implementaciones que has realizado para cumplir con los requisitos y te proporcionar√© mis comentarios de la siguiente manera:\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si todo est√° perfecto.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si tu c√≥digo est√° bien pero se puede mejorar o hay alg√∫n detalle que le hace falta.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si de pronto hace falta algo o existe alg√∫n problema con tu c√≥digo o conclusiones.\n",
    "</div>\n",
    "\n",
    "Puedes responderme de esta forma:\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Respuesta del estudiante</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "</div>\n",
    "\n",
    "</br>\n",
    "\n",
    "**¬°Empecemos!**  &#x1F680;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se busca el calculo de la eficiencia de una minera de extracci√≥n de oro por Zyfra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librer√≠as a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import (make_scorer, mean_absolute_error)\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datasets a trabajar\n",
    "try:\n",
    "    train = pd.read_csv('gold_recovery_train.csv')\n",
    "    test = pd.read_csv('gold_recovery_test.csv')\n",
    "    full = pd.read_csv('gold_recovery_full.csv')\n",
    "except:\n",
    "    train = pd.read_csv('/datasets/gold_recovery_train.csv')\n",
    "    test = pd.read_csv('/datasets/gold_recovery_test.csv')\n",
    "    full = pd.read_csv('/datasets/gold_recovery_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.info()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.info()\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisando los datos de cada uno de los conjuntos de datos se trabajar√° lo siguiente:\n",
    "    1.- Columna `data` se transformar√° a DateTime en los tres datasets.\n",
    "    2.- Verificar los valores ausentes, al no tener los datos completos se eliminar√°n las filas con valores ausentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trabajar√° la columna `data` para transforma a tipo DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "full['date'] = pd.to_datetime(full['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan los valores ausentes en los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "full = full.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se buscar√° usar las mismas columnas en cada dataset para realizar el an√°lisis de mejor forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_test = list(test.columns.values)+ ['rougher.output.recovery','final.output.recovery']\n",
    "train_df = train.loc[:,list_test]\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean las columnas de target a usar para entrenar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = full[['date','rougher.output.recovery','final.output.recovery']]\n",
    "test_df = test.merge(target_columns, how='left', on='date')\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de recuperados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar que el c√°lculo de recuperados es correcto se realizar√° un c√°lculo con las siguientes columnas:\n",
    "\n",
    "    - rougher.input.infeed_au La cual es la concentraci√≥n inicial de oro alimentado.\n",
    "    - rougher.output.concentrate_au Concentraci√≥n de oro antes de la flotaci√≥n.\n",
    "    - rougher.output.tail_au Concentraci√≥n de oro despu√©s de la flotaci√≥n.\n",
    "\n",
    "Con estos datos se va a calcular el porcentaje de oro para cada fila del data set train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funci√≥n para calculo de procentaje de oro\n",
    "\n",
    "def calculo_concentrado(ini_au, conc_au, tail_au):\n",
    "    recuperado = (conc_au*(ini_au-tail_au))/(ini_au*(conc_au-tail_au))*100\n",
    "    print(recuperado.head())\n",
    "    return recuperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valores presentados en dataset\n",
    "recovery = train['rougher.output.recovery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrado = train['rougher.output.concentrate_au']\n",
    "alimentacion = train['rougher.input.feed_au']\n",
    "colas = train['rougher.output.tail_au']\n",
    "\n",
    "recuperado_calculado = calculo_concentrado(alimentacion,concentrado,colas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula el Error absoluto medio de recuperado_calculado contra recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(recuperado_calculado, recovery)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error es tan peque√±o que nuestro c√°lculo de porcentaje de recuperaci√≥n de oro es correcto, por lo que procederemos a lo siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis set de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset de prueba, no contiene las columnas referentes a la concentraci√≥n de plata, plomo, solvente, oro finales.\n",
    "As√≠ mismo tampoco tiene los datos finales de las colas de plata, plomo, solvente y oro.\n",
    "Para tener todas las caracter√≠sticas las columnas floatbank10_sulfate_to_au_feed, floatbank11_sulfate_to_au_feed, and au_pb_ratio tambi√©n est√°n ausentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lisis de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C√°lculo de concentraciones por metal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definir√° una funci√≥n para mostrar los cambios de concentraci√≥n de los diferentes metales (oro, plata, plomo) en las diferentes etapas del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metal_conc(data, etapas):\n",
    "    for etapa in etapas:\n",
    "        data[etapa].hist(legend=True, figsize=(9,6),alpha=0.65)\n",
    "        plt.xlabel(\"Concentraci√≥n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se definen las concentraciones de los metales en las diferentes etapas:\n",
    "\n",
    "etapa_oro = ['rougher.output.concentrate_au',\n",
    "             'primary_cleaner.output.concentrate_au',\n",
    "             'secondary_cleaner.output.tail_au',\n",
    "             'final.output.concentrate_au']\n",
    "\n",
    "etapa_plata = ['rougher.output.concentrate_ag',\n",
    "               'primary_cleaner.output.concentrate_ag',\n",
    "               'secondary_cleaner.output.tail_ag',\n",
    "               'final.output.concentrate_ag']\n",
    "\n",
    "etapa_plomo = ['rougher.output.concentrate_pb',\n",
    "               'primary_cleaner.output.concentrate_pb',\n",
    "               'secondary_cleaner.output.tail_pb',\n",
    "               'final.output.concentrate_pb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metal_conc(train,etapa_oro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_conc(train,etapa_plata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_conc(train,etapa_plomo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se muestra en los histrogramas, conforme avanza el proceso se espera tener una mayor concentraci√≥n de oro, mientras que la concentraci√≥n de plata y plomo disminuyen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tama√±o de part√≠culas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a comparar el tama√±o de part√≠cula en los dataset de entrenamiento *(train)* y de prueba *(test)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rougher.input.feed_size'].hist(bins=50, \n",
    "                                      alpha=0.5, \n",
    "                                      label=\"Tama√±o de part√≠cula entrenamiento\")\n",
    "\n",
    "test['rougher.input.feed_size'].hist(bins=50, \n",
    "                                     alpha=0.5, \n",
    "                                     label=\"Tama√±o de part√≠cula prueba\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Tama√±o de part√≠cula\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El histograma no muestra gran diferencia en la frecuencia de los tama√±os de part√≠culas por lo que los c√°lculos de estimaciones ser√°n consistentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Concentraci√≥n de mezcla a diferentes etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se graficar√°n la sumas de las concentraciones de los metales en diferentes etapas, esto con el fin de determinar los valores fuera de rango que causar√≠an ruido en nuestro modelo de predicci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando del dataset full realizaremos los histogramas\n",
    "\n",
    "full['total_mixture'] = full[['rougher.input.feed_au',\n",
    "                              'rougher.input.feed_ag',\n",
    "                              'rougher.input.feed_pb']].sum(axis=1, skipna=True)\n",
    "full['total_mixture'].hist(bins=30, figsize=(9,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['total_roughermix'] = full[['rougher.output.concentrate_au',\n",
    "                                 'rougher.output.concentrate_ag',\n",
    "                                 'rougher.output.concentrate_pb']].sum(axis=1,skipna=True)\n",
    "full['total_roughermix'].hist(bins=30, figsize=(9,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['total_finalmix'] = full[['final.output.concentrate_au',\n",
    "                                 'final.output.concentrate_ag',\n",
    "                                 'final.output.concentrate_pb']].sum(axis=1,skipna=True)\n",
    "full['total_finalmix'].hist(bins=30, figsize=(9,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los histrogramas nos muestran muchos valores fuera de rango, por lo que los removeremos para no causar ruido en nuestros calculos. Tambi√©n se muestra que los datos est√°n cargados hacia la derecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para buscar los valores fuera de rangos u outliers, se realizar√° un c√°lculo de los valores intercuartiles\n",
    "\n",
    "def outliers_drop(data, columnas):\n",
    "    mapeo = defaultdict(list)\n",
    "    for columna in columnas:\n",
    "        q1 = data[columna].quantile(0.25)\n",
    "        q3 = data[columna].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        minimo = q1-1.5*iqr\n",
    "        maximo = q3+1.5*iqr\n",
    "        mapeo[columna] = (minimo, maximo)\n",
    "    df = data\n",
    "    for a, b in mapeo.items():\n",
    "        df = df.loc[(df[a] > b[0]) & (df[a] < b[1])]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = ['total_mixture','total_roughermix','total_finalmix']\n",
    "\n",
    "print(full.shape)\n",
    "\n",
    "full_fin = outliers_drop(full, parametros)\n",
    "\n",
    "print(full_fin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestran los histogramas nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fin['total_mixture'].hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fin['total_roughermix'].hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fin['total_finalmix'].hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con los datos m√°s parecidos a una distribuci√≥n normal, procederemos a entrenar y probar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se agrega la columna total_mixture al dataset de entrenamiento\n",
    "columnas = full_fin[['date','total_mixture']]\n",
    "train_final = train_df.merge(columnas, how='left', on='date')\n",
    "train_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se quitan las filas con valores nulos en total_mixture\n",
    "train_final = train_final[train_final.total_mixture.notnull()]\n",
    "train_final = train_final.drop(['total_mixture'], axis=1)\n",
    "train_final.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se har√° lo mismo con el dataset de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = test_df.merge(columnas, how='left', on='date')\n",
    "test_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = test_final[test_final.total_mixture.notnull()]\n",
    "test_final = test_final.drop(['total_mixture'], axis=1)\n",
    "test_final.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos datasets trabajaremos los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "¬°Muy bien! üëèüëè Los c√°lculos de esta secci√≥n est√°n correctos y eso es un gran logro. Sigue as√≠ y ver√°s c√≥mo poco a poco te ir√°s convirtiendo en un experto en esta √°rea. üí™üíª</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado y Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C√°lculo de sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_cal(target, prediction):\n",
    "    \n",
    "    def smape(target, prediction):\n",
    "        smape = np.mean((np.abs(target-prediction)/((np.abs(target)+np.abs(prediction))/2)))*100\n",
    "        return smape\n",
    "    \n",
    "    smape_r = smape(target[:,0],prediction[:,0])\n",
    "    smape_f = smape(target[:,1],prediction[:,1])\n",
    "    smape_final = 0.25*smape_r + 0.75*smape_f\n",
    "    return smape_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "La funci√≥n est√° correctamente definida. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caracter√≠sticas y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['rougher.output.recovery','final.output.recovery']\n",
    "\n",
    "train_features = train_final.drop(targets, axis=1)\n",
    "train_target = train_final[targets]\n",
    "\n",
    "test_features = test_final.drop(targets,axis=1)\n",
    "test_target = test_final[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_scorer = make_scorer(smape_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = train_features.set_index('date')\n",
    "test_features = test_features.set_index('date')\n",
    "\n",
    "features = list(train_features.columns)\n",
    "scaler.fit(train_features[features])\n",
    "\n",
    "train_features[features] = scaler.transform(train_features[features])\n",
    "test_features[features] = scaler.transform(test_features[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Perfecto! Preveniste el data leakage. El escalado de datos se realiza por separado para los conjuntos de entrenamiento y prueba.\n",
    "Cuando escalas tus datos, est√°s ajustando sus valores para que tengan una escala uniforme.\n",
    "Imagina esto: Si escalas todo el conjunto de datos (entrenamiento + prueba) juntos, es posible que los valores de prueba influyan en la escala de entrenamiento y viceversa.\n",
    "    \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model = RandomForestRegressor(random_state=1234, n_estimators=15)\n",
    "\n",
    "rfr_train_smape = cross_validate(rfr_model, train_features, train_target.to_numpy(), scoring=smape_scorer, cv=5)\n",
    "\n",
    "for a,b in rfr_train_smape.items():\n",
    "    print(a,b)\n",
    "\n",
    "score_final = rfr_train_smape['test_score']\n",
    "print(\"sMAPE promedio: \", np.sum(score_final)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_train_smape = cross_validate(lr_model, \n",
    "                                train_features, \n",
    "                                train_target.to_numpy(), \n",
    "                                scoring=smape_scorer, \n",
    "                                cv=5)\n",
    "\n",
    "for a,b in lr_train_smape.items():\n",
    "    print(a,b)\n",
    "\n",
    "score_final = lr_train_smape['test_score']\n",
    "print(\"sMAPE promedio: \", np.sum(score_final)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(1,15):\n",
    "    dcr_model = DecisionTreeRegressor(random_state=1234, max_depth=depth)\n",
    "    \n",
    "    dcr_train_smape = cross_validate(dcr_model, \n",
    "                                     train_features, \n",
    "                                     train_target.to_numpy(), \n",
    "                                     scoring=smape_scorer, \n",
    "                                     cv=5)\n",
    "    \n",
    "    for a,b in dcr_train_smape.items():\n",
    "        print(a,b)\n",
    "\n",
    "    score_final = dcr_train_smape['test_score']\n",
    "    print(\"Depth: \", depth)\n",
    "    print(\"sMAPE promedio: \", np.sum(score_final)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo DecisionTreeRegresor es el que nos arroja menor sMAPE, con una profundidad m√°xima de 1, por lo que utilizaremos estos valores para entrenar y probar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "\n",
    "He revisado tu implementaci√≥n de los modelos RandomForestRegressor, LinearRegression y DecisionTreeRegressor, y quisiera destacar varios aspectos positivos de tu enfoque.\n",
    "\n",
    "1. <b>Selecci√≥n de Modelos y Par√°metros:</b> Has hecho un excelente trabajo al seleccionar una variedad de modelos  de regress√≥n. para probar en tu conjunto de datos\n",
    "\n",
    "2. <b>Uso de Cross-Validation:</b> Tu implementaci√≥n de validaci√≥n cruzada fue adecuada. \n",
    "\n",
    "3. <b>Implementaci√≥n del sMAPE Custom Scorer:</b> La utilizaci√≥n del sMAPE (Symmetric Mean Absolute Percentage Error) como m√©trica es adecuada para problemas de regresi√≥n, especialmente en contextos donde los errores relativos son m√°s importantes. Adem√°s, la creaci√≥n de un 'scorer' personalizado para esta m√©trica demuestra un nivel avanzado de habilidad en la manipulaci√≥n de datos y evaluaci√≥n de modelos.\n",
    "\n",
    "4. <b>An√°lisis y Elecci√≥n del Modelo Final:</b> La decisi√≥n de elegir el modelo con el menor sMAPE promedio es l√≥gica y bien fundamentada. Tu an√°lisis para llegar a esta conclusi√≥n est√° bien articulado y muestra un razonamiento claro.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_model = DecisionTreeRegressor(random_state=1234, max_depth=1)\n",
    "\n",
    "dtr_model.fit(train_features, train_target)\n",
    "\n",
    "predict = dtr_model.predict(test_features)\n",
    "\n",
    "smape = smape_cal(test_target.to_numpy(), predict)\n",
    "print(\"sMAPE: \", smape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo nos un valor sMAPE de 6.589, menor que lo presenta la validaci√≥n cruzada, con esto damos un valor de certidumbre aceptable a nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">    \n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n",
    "    \n",
    "¬°Qu√© gran trabajo has hecho!  &#128077;  Podemos aprobar el proyecto. <br>\n",
    "Has demostrado un excelente conocimiento en la construcci√≥n de modelos, al eliminar variables innecesarias y procesar  los datos antes de entrenar los modelos. <br>\n",
    "<br>Quiero felicitarte por un trabajo excepcional y por la calidad de tu an√°lisis. Te animo a que sigas aprendiendo y desafiando tu potencial en los pr√≥ximos sprints. Estoy seguro de que tus habilidades y conocimientos ser√°n valiosos en el futuro y te permitir√°n abordar problemas cada vez m√°s complejos con √©xito.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
