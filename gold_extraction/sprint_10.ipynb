{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se busca el calculo de la eficiencia de una minera de extracción de oro por Zyfra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import (make_scorer, mean_absolute_error)\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datasets a trabajar\n",
    "try:\n",
    "    train = pd.read_csv('gold_recovery_train.csv')\n",
    "    test = pd.read_csv('gold_recovery_test.csv')\n",
    "    full = pd.read_csv('gold_recovery_full.csv')\n",
    "except:\n",
    "    train = pd.read_csv('/datasets/gold_recovery_train.csv')\n",
    "    test = pd.read_csv('/datasets/gold_recovery_test.csv')\n",
    "    full = pd.read_csv('/datasets/gold_recovery_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.info()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.info()\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisando los datos de cada uno de los conjuntos de datos se trabajará lo siguiente:\n",
    "    1.- Columna `data` se transformará a DateTime en los tres datasets.\n",
    "    2.- Verificar los valores ausentes, al no tener los datos completos se eliminarán las filas con valores ausentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trabajará la columna `data` para transforma a tipo DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "full['date'] = pd.to_datetime(full['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan los valores ausentes en los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "full = full.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se buscará usar las mismas columnas en cada dataset para realizar el análisis de mejor forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_test = list(test.columns.values)+ ['rougher.output.recovery','final.output.recovery']\n",
    "train_df = train.loc[:,list_test]\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean las columnas de target a usar para entrenar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = full[['date','rougher.output.recovery','final.output.recovery']]\n",
    "test_df = test.merge(target_columns, how='left', on='date')\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de recuperados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar que el cálculo de recuperados es correcto se realizará un cálculo con las siguientes columnas:\n",
    "\n",
    "    - rougher.input.infeed_au La cual es la concentración inicial de oro alimentado.\n",
    "    - rougher.output.concentrate_au Concentración de oro antes de la flotación.\n",
    "    - rougher.output.tail_au Concentración de oro después de la flotación.\n",
    "\n",
    "Con estos datos se va a calcular el porcentaje de oro para cada fila del data set train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para calculo de procentaje de oro\n",
    "\n",
    "def calculo_concentrado(ini_au, conc_au, tail_au):\n",
    "    recuperado = (conc_au*(ini_au-tail_au))/(ini_au*(conc_au-tail_au))*100\n",
    "    print(recuperado.head())\n",
    "    return recuperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valores presentados en dataset\n",
    "recovery = train['rougher.output.recovery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrado = train['rougher.output.concentrate_au']\n",
    "alimentacion = train['rougher.input.feed_au']\n",
    "colas = train['rougher.output.tail_au']\n",
    "\n",
    "recuperado_calculado = calculo_concentrado(alimentacion,concentrado,colas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula el Error absoluto medio de recuperado_calculado contra recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(recuperado_calculado, recovery)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error es tan pequeño que nuestro cálculo de porcentaje de recuperación de oro es correcto, por lo que procederemos a lo siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis set de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset de prueba, no contiene las columnas referentes a la concentración de plata, plomo, solvente, oro finales.\n",
    "Así mismo tampoco tiene los datos finales de las colas de plata, plomo, solvente y oro.\n",
    "Para tener todas las características las columnas floatbank10_sulfate_to_au_feed, floatbank11_sulfate_to_au_feed, and au_pb_ratio también están ausentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de concentraciones por metal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definirá una función para mostrar los cambios de concentración de los diferentes metales (oro, plata, plomo) en las diferentes etapas del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metal_conc(data, etapas):\n",
    "    for etapa in etapas:\n",
    "        data[etapa].hist(legend=True, figsize=(9,6),alpha=0.65)\n",
    "        plt.xlabel(\"Concentración\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se definen las concentraciones de los metales en las diferentes etapas:\n",
    "\n",
    "etapa_oro = ['rougher.output.concentrate_au',\n",
    "             'primary_cleaner.output.concentrate_au',\n",
    "             'secondary_cleaner.output.tail_au',\n",
    "             'final.output.concentrate_au']\n",
    "\n",
    "etapa_plata = ['rougher.output.concentrate_ag',\n",
    "               'primary_cleaner.output.concentrate_ag',\n",
    "               'secondary_cleaner.output.tail_ag',\n",
    "               'final.output.concentrate_ag']\n",
    "\n",
    "etapa_plomo = ['rougher.output.concentrate_pb',\n",
    "               'primary_cleaner.output.concentrate_pb',\n",
    "               'secondary_cleaner.output.tail_pb',\n",
    "               'final.output.concentrate_pb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metal_conc(train,etapa_oro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_conc(train,etapa_plata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plomo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_conc(train,etapa_plomo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se muestra en los histrogramas, conforme avanza el proceso se espera tener una mayor concentración de oro, mientras que la concentración de plata y plomo disminuyen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamaño de partículas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a comparar el tamaño de partícula en los dataset de entrenamiento *(train)* y de prueba *(test)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rougher.input.feed_size'].hist(bins=50, \n",
    "                                      alpha=0.5, \n",
    "                                      label=\"Tamaño de partícula entrenamiento\")\n",
    "\n",
    "test['rougher.input.feed_size'].hist(bins=50, \n",
    "                                     alpha=0.5, \n",
    "                                     label=\"Tamaño de partícula prueba\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Tamaño de partícula\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El histograma no muestra gran diferencia en la frecuencia de los tamaños de partículas por lo que los cálculos de estimaciones serán consistentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Concentración de mezcla a diferentes etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se graficarán la sumas de las concentraciones de los metales en diferentes etapas, esto con el fin de determinar los valores fuera de rango que causarían ruido en nuestro modelo de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando del dataset full realizaremos los histogramas\n",
    "\n",
    "full['total_mixture'] = full[['rougher.input.feed_au',\n",
    "                              'rougher.input.feed_ag',\n",
    "                              'rougher.input.feed_pb']].sum(axis=1, skipna=True)\n",
    "full['total_mixture'].hist(bins=30, figsize=(9,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['total_roughermix'] = full[['rougher.output.concentrate_au',\n",
    "                                 'rougher.output.concentrate_ag',\n",
    "                                 'rougher.output.concentrate_pb']].sum(axis=1,skipna=True)\n",
    "full['total_roughermix'].hist(bins=30, figsize=(9,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['total_finalmix'] = full[['final.output.concentrate_au',\n",
    "                                 'final.output.concentrate_ag',\n",
    "                                 'final.output.concentrate_pb']].sum(axis=1,skipna=True)\n",
    "full['total_finalmix'].hist(bins=30, figsize=(9,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los histrogramas nos muestran muchos valores fuera de rango, por lo que los removeremos para no causar ruido en nuestros calculos. También se muestra que los datos están cargados hacia la derecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para buscar los valores fuera de rangos u outliers, se realizará un cálculo de los valores intercuartiles\n",
    "\n",
    "def outliers_drop(data, columnas):\n",
    "    mapeo = defaultdict(list)\n",
    "    for columna in columnas:\n",
    "        q1 = data[columna].quantile(0.25)\n",
    "        q3 = data[columna].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        minimo = q1-1.5*iqr\n",
    "        maximo = q3+1.5*iqr\n",
    "        mapeo[columna] = (minimo, maximo)\n",
    "    df = data\n",
    "    for a, b in mapeo.items():\n",
    "        df = df.loc[(df[a] > b[0]) & (df[a] < b[1])]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = ['total_mixture','total_roughermix','total_finalmix']\n",
    "\n",
    "print(full.shape)\n",
    "\n",
    "full_fin = outliers_drop(full, parametros)\n",
    "\n",
    "print(full_fin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestran los histogramas nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fin['total_mixture'].hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fin['total_roughermix'].hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fin['total_finalmix'].hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con los datos más parecidos a una distribución normal, procederemos a entrenar y probar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se agrega la columna total_mixture al dataset de entrenamiento\n",
    "columnas = full_fin[['date','total_mixture']]\n",
    "train_final = train_df.merge(columnas, how='left', on='date')\n",
    "train_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se quitan las filas con valores nulos en total_mixture\n",
    "train_final = train_final[train_final.total_mixture.notnull()]\n",
    "train_final = train_final.drop(['total_mixture'], axis=1)\n",
    "train_final.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hará lo mismo con el dataset de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = test_df.merge(columnas, how='left', on='date')\n",
    "test_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = test_final[test_final.total_mixture.notnull()]\n",
    "test_final = test_final.drop(['total_mixture'], axis=1)\n",
    "test_final.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos datasets trabajaremos los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado y Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_cal(target, prediction):\n",
    "    \n",
    "    def smape(target, prediction):\n",
    "        smape = np.mean((np.abs(target-prediction)/((np.abs(target)+np.abs(prediction))/2)))*100\n",
    "        return smape\n",
    "    \n",
    "    smape_r = smape(target[:,0],prediction[:,0])\n",
    "    smape_f = smape(target[:,1],prediction[:,1])\n",
    "    smape_final = 0.25*smape_r + 0.75*smape_f\n",
    "    return smape_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Características y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['rougher.output.recovery','final.output.recovery']\n",
    "\n",
    "train_features = train_final.drop(targets, axis=1)\n",
    "train_target = train_final[targets]\n",
    "\n",
    "test_features = test_final.drop(targets,axis=1)\n",
    "test_target = test_final[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_scorer = make_scorer(smape_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = train_features.set_index('date')\n",
    "test_features = test_features.set_index('date')\n",
    "\n",
    "features = list(train_features.columns)\n",
    "scaler.fit(train_features[features])\n",
    "\n",
    "train_features[features] = scaler.transform(train_features[features])\n",
    "test_features[features] = scaler.transform(test_features[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model = RandomForestRegressor(random_state=1234, n_estimators=15)\n",
    "\n",
    "rfr_train_smape = cross_validate(rfr_model, train_features, train_target.to_numpy(), scoring=smape_scorer, cv=5)\n",
    "\n",
    "for a,b in rfr_train_smape.items():\n",
    "    print(a,b)\n",
    "\n",
    "score_final = rfr_train_smape['test_score']\n",
    "print(\"sMAPE promedio: \", np.sum(score_final)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_train_smape = cross_validate(lr_model, \n",
    "                                train_features, \n",
    "                                train_target.to_numpy(), \n",
    "                                scoring=smape_scorer, \n",
    "                                cv=5)\n",
    "\n",
    "for a,b in lr_train_smape.items():\n",
    "    print(a,b)\n",
    "\n",
    "score_final = lr_train_smape['test_score']\n",
    "print(\"sMAPE promedio: \", np.sum(score_final)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(1,15):\n",
    "    dcr_model = DecisionTreeRegressor(random_state=1234, max_depth=depth)\n",
    "    \n",
    "    dcr_train_smape = cross_validate(dcr_model, \n",
    "                                     train_features, \n",
    "                                     train_target.to_numpy(), \n",
    "                                     scoring=smape_scorer, \n",
    "                                     cv=5)\n",
    "    \n",
    "    for a,b in dcr_train_smape.items():\n",
    "        print(a,b)\n",
    "\n",
    "    score_final = dcr_train_smape['test_score']\n",
    "    print(\"Depth: \", depth)\n",
    "    print(\"sMAPE promedio: \", np.sum(score_final)/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo DecisionTreeRegresor es el que nos arroja menor sMAPE, con una profundidad máxima de 1, por lo que utilizaremos estos valores para entrenar y probar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_model = DecisionTreeRegressor(random_state=1234, max_depth=1)\n",
    "\n",
    "dtr_model.fit(train_features, train_target)\n",
    "\n",
    "predict = dtr_model.predict(test_features)\n",
    "\n",
    "smape = smape_cal(test_target.to_numpy(), predict)\n",
    "print(\"sMAPE: \", smape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo nos un valor sMAPE de 6.589, menor que lo presenta la validación cruzada, con esto damos un valor de certidumbre aceptable a nuestro modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
